import os
import streamlit as st
from dotenv import load_dotenv
import google.generativeai as genai

# --- CONFIGURATION CONSTANTS ---

# Define creator details
CREATOR_NAME = "Ankit Nandoliya"
CREATOR_PORTFOLIO = "https://ankit52-git-main-ankitnandoliya32-8971s-projects.vercel.app/"
CREATOR_KEYWORDS = [
    "who built you", "who made you", "your creator", 
    "your developer", "who created you", "who is ankit", 
    "tell me about ankit", "who is my master", "tell me about yourself"
]

# Detailed profile for the custom response
CREATOR_PROFILE = """
**Ankit Nandoliya** is a software developer focused on full-stack development and artificial intelligence integration. He creates smooth user experiences and stable, scalable backend systems.

**Key Expertise:**
* **Full Stack Development:** Experienced with modern JavaScript frameworks (like React or Angular) and Python/Node.js for backend services.
* **AI/ML Integration:** Works with generative models and APIs to build intelligent applications, like this J.A.R.V.I.S. system.
* **Cloud & Deployment:** Familiar with setting up applications using platforms like Vercel and similar cloud services.

He approaches projects with a focus on problem-solving and attention to detail.
"""

# Use a tool-capable model for real-time information
MODEL_NAME = "gemini-1.5-pro-latest" 


# --- API KEY & MODEL INITIALIZATION ---

# Load environment variables
try:
    load_dotenv()
except ImportError:
    pass 

# Configure API key
api_key = os.getenv("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY")

if not api_key:
    st.error("Configuration Error: GOOGLE_API_KEY not found. Please set it in your .env file or Streamlit Secrets.")
    st.stop()
    
genai.configure(api_key=api_key)

# Initialize the model with the Google Search tool enabled
try:
    # THIS IS THE KEY TO ENABLE REAL-TIME SEARCH.
    # It requires google-generativeai >= 0.5.0.
    model = genai.GenerativeModel(
        MODEL_NAME,
        tools=["google_search"] 
    )
except ValueError as e:
     st.error(
         f"**Initialization Error (MUST FIX):** The AI tool could not be initialized. "
         f"The error '{e}' means your `google-generativeai` library is too old. "
         f"**ACTION REQUIRED:** Please update your `requirements.txt` file to include: "
         f"`google-generativeai>=0.5.0` and **redeploy your app**."
     )
     st.stop()


# --- STREAMLIT APP SETUP ---

# Streamlit page settings
st.set_page_config(
    page_title="J.A.R.V.I.S.",
    page_icon="ðŸ’»",
    layout="centered",
)

st.title("ðŸ’» J.A.R.V.I.S. AI System")

# Chat history stored in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
    # INITIAL GREETING MESSAGE
    st.session_state.messages.append({
        "role": "assistant",
        "text": "Greetings, I am J.A.R.V.I.S. How may I assist you today?"
    })

# Display past messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["text"])

# Chat input
user_input = st.chat_input("Type your message...")

if user_input:
    # Display user message
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "text": user_input})

    ai_text = ""
    
    # 1. Custom Question Handling (Bypass API for fixed responses)
    is_creator_query = any(keyword in user_input.lower() for keyword in CREATOR_KEYWORDS)

    if is_creator_query:
        # Hardcoded response for creator identity
        ai_text = (
            f"I was built by the developer, **{CREATOR_NAME}**. "
            f"\n\n--- **Creator Profile and History** ---\n\n"
            f"{CREATOR_PROFILE}"
            f"\n\nFor more details on his projects and technical background, please visit his portfolio here: **[{CREATOR_PORTFOLIO}]({CREATOR_PORTFOLIO})**"
        )
    else:
        # 2. Normal Gemini API Call
        try:
            # Format the entire conversation history (for memory)
            contents = []
            for msg in st.session_state.messages:
                # The API expects role 'model' for the assistant's responses
                role = "user" if msg["role"] == "user" else "model" 
                
                contents.append(
                    {"role": role, "parts": [{"text": msg["text"]}]}
                )
            
            # Call generate_content with history (memory)
            # The model will use the 'google_search' tool automatically when needed
            response = model.generate_content(contents) 
            ai_text = response.text

        except Exception as e:
            # Fallback if API call fails
            st.error(f"I encountered an error trying to access the AI: {e}")
            ai_text = "My systems are currently experiencing a brief technical fault. Please try again."

    # 3. Display and Save AI response
    if ai_text:
        with st.chat_message("assistant"):
            st.markdown(ai_text)
            
        # Save AI response in session
        st.session_state.messages.append({"role": "assistant", "text": ai_text})
